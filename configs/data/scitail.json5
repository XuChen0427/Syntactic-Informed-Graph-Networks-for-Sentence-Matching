{
    data_dir: 'data/scitail',
    output_dir: 'scitail_SIGN',
    bert_config_dir: 'modeling_bert/bert-large-uncased-config.json',
    bert_model_dir: 'modeling_bert/bert-large-uncased-pytorch_model.bin',
    bert_vocal_dir: 'modeling_bert/bert-base-uncased-vocab.txt',
    graph_dir: 'hetegraphs/scitail',
    metric: 'acc',
    data_name: 'scitail',
    node_dir: 'scitail_node.out',
    watch_metrics: [],

    model: {
        prediction: 'full',
        filelength: 4,
        num_classes: 2,
        n_type: 5,
        hidden_size: '200~600', //tuned among
    },

    routine: {
        eval_per_samples: 12800,
        eval_warmup_samples: 5120000,
        eval_per_samples_warmup: 512000,
        min_samples: 5120000,
        tolerance_samples: 2560000,
        epochs: '5~15', //tuned among
        total_data: 28000,
    },

    optim: {
        lr: '1e-5~5e-5',  //tuned among,
        gcn_lr: '1e-5~5e-5',  //tuned among,
        warmup_rate: '0.1~0.2', //tuned among,
        gcn_min_lr: 1e-5,
        min_lr: 5e-6,
        lr_decay_samples: 800000,
        batch_size: '16~128',  //tuned among,
        lr_warmup_samples: 1200000,
        dropout: 0.2,
        gat_layernum: '1~3',  //tuned among,
    }
}